{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### installing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (0.4.21)\n",
      "Requirement already satisfied: google-cloud-bigquery in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (3.14.1)\n",
      "Requirement already satisfied: pandas in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (2.1.4)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.0.353-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: google-cloud-aiplatform in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (1.38.1)\n",
      "Requirement already satisfied: gradio in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (4.12.0)\n",
      "Requirement already satisfied: requests>=2.28 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (2.5.3)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (0.108.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (1.26.3)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (4.9.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (3.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (1.16.3)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (0.15.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (4.66.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (6.1.1)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (1.60.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (4.1.2)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (28.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from chromadb) (4.0.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-cloud-bigquery) (2.15.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-cloud-bigquery) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-cloud-bigquery) (2.7.0)\n",
      "Requirement already satisfied: packaging>=20.0.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-cloud-bigquery) (23.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-cloud-bigquery) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from pandas) (2023.4)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.25-cp39-cp39-macosx_10_9_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.9.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Using cached dataclasses_json-0.6.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.2 (from langchain)\n",
      "  Downloading langchain_community-0.0.7-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.4 (from langchain)\n",
      "  Downloading langchain_core-0.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.70 (from langchain)\n",
      "  Downloading langsmith-0.0.77-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-cloud-aiplatform) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-cloud-aiplatform) (4.25.1)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-cloud-aiplatform) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-cloud-aiplatform) (1.11.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-cloud-aiplatform) (2.0.2)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio) (5.2.0)\n",
      "Requirement already satisfied: ffmpy in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio) (0.3.1)\n",
      "Requirement already satisfied: gradio-client==0.8.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio) (0.8.0)\n",
      "Requirement already satisfied: httpx in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio) (0.26.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio) (0.20.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio) (3.8.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio) (3.9.10)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: pydub in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: fsspec in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio-client==0.8.0->gradio) (2023.12.2)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from gradio-client==0.8.0->gradio) (11.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.4-cp39-cp39-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from altair<6.0,>=4.2.0->gradio) (4.20.0)\n",
      "Requirement already satisfied: toolz in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: starlette<0.33.0,>=0.29.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from fastapi>=0.95.2->chromadb) (0.32.0.post1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.62.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (2.26.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.60.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.5.0)\n",
      "Requirement already satisfied: filelock in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from importlib-resources->chromadb) (3.17.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (2023.11.17)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3<2.0,>=1.24.2 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.4->langchain) (4.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
      "Requirement already satisfied: coloredlogs in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: sympy in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.22.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.22.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.43b0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.43b0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.43b0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (58.0.4)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from opentelemetry-instrumentation-asgi==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from pydantic>=1.9->chromadb) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from requests>=2.28->chromadb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from requests>=2.28->chromadb) (3.6)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.0.3-cp39-cp39-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from httpx->gradio) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.4->langchain) (1.2.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (4.9)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.16.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.17.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/jskuratowicz/Projects/DataGenAIHackaton/.venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (0.5.1)\n",
      "Downloading langchain-0.0.353-py3-none-any.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.1/803.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached aiohttp-3.9.1-cp39-cp39-macosx_10_9_x86_64.whl (397 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.4-py3-none-any.whl (205 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.7/205.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.0.77-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.25-cp39-cp39-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached frozenlist-1.4.1-cp39-cp39-macosx_10_9_x86_64.whl (55 kB)\n",
      "Using cached greenlet-3.0.3-cp39-cp39-macosx_11_0_universal2.whl (269 kB)\n",
      "Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Using cached marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.9.4-cp39-cp39-macosx_10_9_x86_64.whl (83 kB)\n",
      "Installing collected packages: mypy-extensions, multidict, marshmallow, jsonpointer, greenlet, frozenlist, async-timeout, yarl, typing-inspect, SQLAlchemy, jsonpatch, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-community, langchain\n",
      "Successfully installed SQLAlchemy-2.0.25 aiohttp-3.9.1 aiosignal-1.3.1 async-timeout-4.0.3 dataclasses-json-0.6.3 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.353 langchain-community-0.0.7 langchain-core-0.1.4 langsmith-0.0.77 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 typing-inspect-0.9.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "#!pip install chromadb google-cloud-bigquery pandas langchain google-cloud-aiplatform gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import requests\n",
    "from google.oauth2 import service_account\n",
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we will be looking for data in public bigquery datasets\n",
    "\n",
    "We're creating explicit list of tables to search for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bqclient = bigquery.Client(project='bigquery-public-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project_ref = bqclient.project('bigquery-public-data')\n",
    "\n",
    "table_list=[\n",
    "    {'dataset': 'iowa_liquor_sales', 'table': 'sales'},\n",
    "    {'dataset': 'london_bicycles', 'table': 'cycle_hire'},\n",
    "    {'dataset': 'london_bicycles', 'table': 'cycle_stations'},\n",
    "    {'dataset': 'ml_datasets', 'table': 'census_adult_income'},\n",
    "    {'dataset': 'ml_datasets', 'table': 'credit_card_default'},\n",
    "    {'dataset': 'ml_datasets', 'table': 'holidays_and_events_for_forecasting'},\n",
    "    {'dataset': 'ml_datasets', 'table': 'iris'},\n",
    "    {'dataset': 'ml_datasets', 'table': 'penguins'},\n",
    "    {'dataset': 'ml_datasets', 'table': 'ulb_fraud_detection'},\n",
    "    {'dataset': 'new_york_citibike', 'table': 'citibike_stations'},\n",
    "    {'dataset': 'new_york_citibike', 'table': 'citibike_trips'},\n",
    "    {'dataset': 'fdic_banks', 'table': 'institutions'},\n",
    "    {'dataset': 'fdic_banks', 'table': 'locations'},\n",
    "    {'dataset': 'fda_food', 'table': 'food_enforcement'},\n",
    "    {'dataset': 'fda_food', 'table': 'food_events'},\n",
    "    {'dataset': 'fcc_political_ads', 'table': 'broadcast_tv_radio_station'},\n",
    "    {'dataset': 'fcc_political_ads', 'table': 'content_info'},\n",
    "    {'dataset': 'fcc_political_ads', 'table': 'file_history'},\n",
    "    {'dataset': 'fcc_political_ads', 'table': 'file_record'},\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're using a variable to generate missing table descriptions using Text Bison\n",
    "if True then generate missing table descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "GENERATE_TABLE_DESCRIPTIONS = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that sticks together dataset,table,field descriptions\n",
    "if GENERATE_TABLE_DESCRIPTIONS is true then missing table descriptions are generated in bison based on other descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_description(dataset_ref, table_ref,GENERATE_TABLE_DESCRIPTIONS):\n",
    "    table=bqclient.get_table(table_ref)\n",
    "    dataset=bqclient.get_dataset(dataset_ref)\n",
    "    description=f\"Dataset name: '{dataset_ref.dataset_id}', Dataset description:'{dataset.description}', Table name:\\\"{str(table_ref.table_id).replace('_',' ')}\\\", Table description:'{table.description}'\"\n",
    "    description=description + \"Schema attributes: \" + \",\".join([f\"column-name: {field.name}, column-type:\\\"{field.field_type}\\\" ,column-description: \\\"{field.description}\\\"\" for field in table.schema])\n",
    "    \n",
    "    if table.description is None:\n",
    "        returned_table_description=\"No description available\"\n",
    "    else:\n",
    "        returned_table_description=table.description\n",
    "        \n",
    "    if GENERATE_TABLE_DESCRIPTIONS and table.description is None:\n",
    "        parameters = {\n",
    "            \"temperature\": 0.9,  # Temperature controls the degree of randomness in token selection.\n",
    "            \"max_output_tokens\": 1000,  # Token limit determines the maximum amount of text output.\n",
    "            \"top_p\": 0.8,  # Tokens are selected from most probable to least until the sum of their probabilities equals the top_p value.\n",
    "            \"top_k\": 40,  # A top_k of 1 means the selected token is the most probable among all tokens.\n",
    "        }\n",
    "        model = TextGenerationModel.from_pretrained(\"text-bison@002\")\n",
    "        response = model.predict(\n",
    "            \"Please give brief description of a table that describes contents and purpose of the table for table users. Please do not describe or list attributes of a table only table general description. This is table schema:\" + description,\n",
    "            **parameters,\n",
    "        )\n",
    "        print(f\"Response from Model: {response.text}\")\n",
    "        description=f\"Dataset name: '{dataset_ref.dataset_id}', Dataset description:'{dataset.description}', Table name:\\\"{str(table_ref.table_id).replace('_',' ')}\\\", Table description:'{response.text}'\"\n",
    "        description=description + \"Schema attributes: \" + \",\".join([f\"column-name: {field.name}, column-type:\\\"{field.field_type}\\\" ,column-description: \\\"{field.description}\\\"\" for field in table.schema])\n",
    "        returned_table_description=response.text\n",
    "\n",
    "    return returned_table_description,description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble table description\n",
    "Calling the above function for each table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model:  The table \"cycle hire\" in the dataset \"london_bicycles\" provides information about bicycle trips in London. Each row in the table represents a single bike trip. The table includes the following columns:\n",
      "\n",
      "- rental_id: Unique identifier for each bike trip.\n",
      "- duration: Duration of the bike trip in seconds.\n",
      "- duration_ms: Duration of the bike trip in milliseconds.\n",
      "- bike_id: Unique identifier for each bike.\n",
      "- bike_model: Model of the bike used for the trip.\n",
      "- end_date: Date and time when the bike trip ended.\n",
      "- end_station_id: Unique identifier for the station where the bike trip ended.\n",
      "- end_station_name: Name of the station where the bike trip ended.\n",
      "- start_date: Date and time when the bike trip started.\n",
      "- start_station_id: Unique identifier for the station where the bike trip started.\n",
      "- start_station_name: Name of the station where the bike trip started.\n",
      "- end_station_logical_terminal: Logical terminal for the station where the bike trip ended.\n",
      "- start_station_logical_terminal: Logical terminal for the station where the bike trip started.\n",
      "- end_station_priority_id: Priority ID for the station where the bike trip ended.\n",
      "Response from Model:  The table named \"cycle stations\" in the 'london_bicycles' dataset contains information about bicycle stations in London. It has 15 columns: id, installed, latitude, locked, longitude, name, bikes_count, docks_count, nbEmptyDocks, temporary, terminal_name, install_date, removal_date. Each row in the table represents a bicycle station, and the columns provide various details about the station such as its location, status, and capacity.\n",
      "Response from Model:  The table describes the contents and purpose of the 'census adult income' table in the 'ml_datasets' dataset. It provides information about the attributes of the table, including column names, data types, and descriptions. The table contains information about individuals, including their age, work class, education level, marital status, occupation, relationship to the household, race, gender, capital gains, capital losses, hours worked per week, country of birth, and income bracket. This dataset can be used for various machine learning tasks, such as income prediction and demographic analysis.\n",
      "Response from Model:  The table \"credit card default\" in the \"ml_datasets\" dataset contains information about credit card holders and their payment history. It has 24 columns, including the anonymized ID of each client, credit limit, gender, education level, marital status, age, repayment status for the past 6 months, bill statement amounts for the past 6 months, previous payment amounts for the past 6 months, and an indicator for whether the client defaulted on the next month's payment. The table also includes a predicted default payment column, which is a nested record. The purpose of this table is to provide data for training and evaluating machine learning models to predict credit card defaults.\n",
      "Response from Model:  **Table: iris**\n",
      "\n",
      "**Description**: The iris table contains measurements of the sepal and petal lengths and widths of three species of iris flowers.\n",
      "\n",
      "**Purpose**: The purpose of the iris table is to provide a dataset for machine learning algorithms to use in classification tasks.\n",
      "Response from Model:  This table contains information about penguins.\n",
      "Each row in the table represents a single penguin and contains the following information:\n",
      "- species: The species of the penguin.\n",
      "- island: The island where the penguin was found.\n",
      "- culmen_length_mm: The length of the penguin's culmen (beak) in millimeters.\n",
      "- culmen_depth_mm: The depth of the penguin's culmen (beak) in millimeters.\n",
      "- flipper_length_mm: The length of the penguin's flipper in millimeters.\n",
      "- body_mass_g: The body mass of the penguin in grams.\n",
      "- sex: The sex of the penguin.\n",
      "Response from Model:  The table 'citibike_stations' in the dataset 'new_york_citibike' contains information about the Citi Bike stations in New York City. Each row in the table represents a single station, and the columns provide details such as station ID, name, location (latitude and longitude), region ID, rental methods accepted, available capacity, number of bikes available and disabled, number of docks available and disabled, and whether the station is currently installed, renting or returning bikes. The 'last_reported' column indicates the last time the station reported its status.\n",
      "Response from Model:  The table 'citibike_trips' in the dataset 'new_york_citibike' contains information about bike trips in New York City. Each row in the table represents a single trip and includes details such as trip duration, start and end times, station IDs and names, bike ID, user type, birth year, gender, and customer plan. This data can be used to analyze bike usage patterns, identify popular routes, and plan for future bike infrastructure improvements.\n",
      "Response from Model:  This\n",
      "Response from Model:  The table describes the various physical locations of banks insured by the FDIC. Each row represents a branch or main office of an FDIC-insured institution. The table includes information such as the FDIC certificate number, institution name, branch name, branch address, city, state, zip code, county, county FIPS code, state abbreviation, state name, institution class, Core Based Statistical Area (CBSA) code, CBSA name, CBSA division flag, CBSA division code, CBSA division name, CBSA metro flag, CBSA metro code, CBSA metro name, CBSA micro flag, Combined Statistical Area (CSA) flag, CSA code, CSA name, date established, FDIC UNINUM, last updated date, service type, and branch FDIC UNINUM.\n",
      "Response from Model:  The 'food enforcement' table in the 'fda_food' dataset contains information about food recalls issued by the U.S. Food and Drug Administration (FDA). Each row in the table represents a specific recall event and provides details such as the classification of the recall, the date of the recall report, the date the recall was initiated, the recall number, the city and state of the recalling firm, the reason for the recall, the initial firm notification method, the status of the recall, the product type, the product description, and more. This table can be used to analyze trends in food recalls, identify potential health hazards, and monitor the effectiveness of the FDA's food safety efforts.\n",
      "Response from Model:  The table \"food events\" in the \"fda_food\" dataset contains information about adverse events related to food products reported to the US Food and Drug Administration (FDA). Each row in the table represents an individual event report. The table includes columns for the report number, information on reactions or symptoms experienced, known outcomes or consequences of the event, brand name of the product, FDA industry code and name associated with the product, date the report was received by the FDA, date of the adverse event, reported gender and age of the consumer, as well as the unit in which the consumer's age is expressed. This table can be used to analyze and understand the nature and frequency of adverse events related to food products, identify trends and patterns, and support regulatory decision-making and public health interventions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in table_list:\n",
    "    \n",
    "    \n",
    "    dataset_ref = bqclient.dataset(i['dataset'])\n",
    "    table_ref = dataset_ref.table(i['table'])\n",
    "    dataset=bqclient.get_dataset(dataset_ref)\n",
    "    table=bqclient.get_table(table_ref)\n",
    "    #print(assemble_description(dataset_ref, table_ref))\n",
    "    i['table_description'],i['description']=assemble_description(dataset_ref, table_ref,GENERATE_TABLE_DESCRIPTIONS)\n",
    "    #print(dataset_ref,table_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings from descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import langchain\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from vertexai.language_models import TextEmbeddingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chromaclient = chromadb.Client()\n",
    "collection = chromaclient.get_or_create_collection(\"my_tables\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load embeddings into vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import VertexAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#VAIembeddings=VertexAIEmbeddings(model_name='textembedding-gecko@002')\n",
    "#model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@002\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're not calling embedding functions ourselves. \n",
    "We point ChromaDB to use Vertex Embeddings every time new document is loaded or every time a query to DB is made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for non english embeddings use model_name=textembedding-gecko-multilingual@001\n",
    "\n",
    "db=Chroma(client=chromaclient,collection_name='my_tables',embedding_function=VertexAIEmbeddings(model_name='textembedding-gecko@001',task_type=\"SEMANTIC_SIMILARITY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "\n",
    "for i in table_list:\n",
    "    doc=Document(page_content=i['description'],metadata={'dataset': i['dataset'],'table': i['table'],'table_description' : i['table_description']},id=i['table'])\n",
    "    db.add_documents( documents=[doc],                    \n",
    "                     ids=[i['table']]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "db.similarity_search_with_relevance_scores(query=\"yummy\", k=5, threshold=0.5, return_relevance_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=db.similarity_search_with_relevance_scores(query=\"bicycles\", k=5, threshold=0.5, return_relevance_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Document(page_content='Dataset name: \\'new_york_citibike\\', Dataset description:\\'None\\', Table name:\"citibike stations\", Table description:\\' The table \\'citibike_stations\\' in the dataset \\'new_york_citibike\\' contains information about the Citi Bike stations in New York City. Each row in the table represents a single station, and the columns provide details such as station ID, name, location (latitude and longitude), region ID, rental methods accepted, available capacity, number of bikes available and disabled, number of docks available and disabled, and whether the station is currently installed, renting or returning bikes. The \\'last_reported\\' column indicates the last time the station reported its status.\\'Schema attributes: column-name: station_id, column-type:\"STRING\" ,column-description: \"Unique identifier of a station.\",column-name: name, column-type:\"STRING\" ,column-description: \"Public name of the station.\",column-name: short_name, column-type:\"STRING\" ,column-description: \"Short name or other type of identifier, as used by the data publisher.\",column-name: latitude, column-type:\"FLOAT\" ,column-description: \"The latitude of station. The field value must be a valid WGS 84 latitude in decimal degrees format.\",column-name: longitude, column-type:\"FLOAT\" ,column-description: \"The longitude of station. The field value must be a valid WGS 84 latitude in decimal degrees format.\",column-name: region_id, column-type:\"INTEGER\" ,column-description: \"ID of the region where station is located.\",column-name: rental_methods, column-type:\"STRING\" ,column-description: \"Array of enumerables containing the payment methods accepted at this station.\",column-name: capacity, column-type:\"INTEGER\" ,column-description: \"ANumber of total docking points installed at this station, both available and unavailable.\",column-name: eightd_has_key_dispenser, column-type:\"BOOLEAN\" ,column-description: \"\",column-name: num_bikes_available, column-type:\"INTEGER\" ,column-description: \"Number of bikes available for rental.\",column-name: num_bikes_disabled, column-type:\"INTEGER\" ,column-description: \"Number of disabled bikes at the station.\",column-name: num_docks_available, column-type:\"INTEGER\" ,column-description: \"Number of docks accepting bike returns.\",column-name: num_docks_disabled, column-type:\"INTEGER\" ,column-description: \"Number of empty but disabled dock points at the station.\",column-name: is_installed, column-type:\"BOOLEAN\" ,column-description: \"Is the station currently on the street?\",column-name: is_renting, column-type:\"BOOLEAN\" ,column-description: \"Is the station currently renting bikes?\",column-name: is_returning, column-type:\"BOOLEAN\" ,column-description: \"Is the station accepting bike returns?\",column-name: eightd_has_available_keys, column-type:\"BOOLEAN\" ,column-description: \"\",column-name: last_reported, column-type:\"TIMESTAMP\" ,column-description: \"Timestamp indicating the last time this station reported its status to the backend, in NYC local time.\"', metadata={'dataset': 'new_york_citibike', 'table': 'citibike_stations', 'table_description': \" The table 'citibike_stations' in the dataset 'new_york_citibike' contains information about the Citi Bike stations in New York City. Each row in the table represents a single station, and the columns provide details such as station ID, name, location (latitude and longitude), region ID, rental methods accepted, available capacity, number of bikes available and disabled, number of docks available and disabled, and whether the station is currently installed, renting or returning bikes. The 'last_reported' column indicates the last time the station reported its status.\"}), 0.48085796363470024)\n",
      "(Document(page_content='Dataset name: \\'london_bicycles\\', Dataset description:\\'None\\', Table name:\"cycle stations\", Table description:\\' The table named \"cycle stations\" in the \\'london_bicycles\\' dataset contains information about bicycle stations in London. It has 15 columns: id, installed, latitude, locked, longitude, name, bikes_count, docks_count, nbEmptyDocks, temporary, terminal_name, install_date, removal_date. Each row in the table represents a bicycle station, and the columns provide various details about the station such as its location, status, and capacity.\\'Schema attributes: column-name: id, column-type:\"INTEGER\" ,column-description: \"None\",column-name: installed, column-type:\"BOOLEAN\" ,column-description: \"None\",column-name: latitude, column-type:\"FLOAT\" ,column-description: \"None\",column-name: locked, column-type:\"STRING\" ,column-description: \"None\",column-name: longitude, column-type:\"FLOAT\" ,column-description: \"None\",column-name: name, column-type:\"STRING\" ,column-description: \"None\",column-name: bikes_count, column-type:\"INTEGER\" ,column-description: \"None\",column-name: docks_count, column-type:\"INTEGER\" ,column-description: \"None\",column-name: nbEmptyDocks, column-type:\"INTEGER\" ,column-description: \"None\",column-name: temporary, column-type:\"BOOLEAN\" ,column-description: \"None\",column-name: terminal_name, column-type:\"STRING\" ,column-description: \"None\",column-name: install_date, column-type:\"DATE\" ,column-description: \"None\",column-name: removal_date, column-type:\"DATE\" ,column-description: \"None\"', metadata={'dataset': 'london_bicycles', 'table': 'cycle_stations', 'table_description': ' The table named \"cycle stations\" in the \\'london_bicycles\\' dataset contains information about bicycle stations in London. It has 15 columns: id, installed, latitude, locked, longitude, name, bikes_count, docks_count, nbEmptyDocks, temporary, terminal_name, install_date, removal_date. Each row in the table represents a bicycle station, and the columns provide various details about the station such as its location, status, and capacity.'}), 0.4566720789104207)\n",
      "(Document(page_content='Dataset name: \\'new_york_citibike\\', Dataset description:\\'None\\', Table name:\"citibike trips\", Table description:\\' The table \\'citibike_trips\\' in the dataset \\'new_york_citibike\\' contains information about bike trips in New York City. Each row in the table represents a single trip and includes details such as trip duration, start and end times, station IDs and names, bike ID, user type, birth year, gender, and customer plan. This data can be used to analyze bike usage patterns, identify popular routes, and plan for future bike infrastructure improvements.\\'Schema attributes: column-name: tripduration, column-type:\"INTEGER\" ,column-description: \"Trip Duration (in seconds)\",column-name: starttime, column-type:\"DATETIME\" ,column-description: \"Start Time, in NYC local time.\",column-name: stoptime, column-type:\"DATETIME\" ,column-description: \"Stop Time, in NYC local time.\",column-name: start_station_id, column-type:\"INTEGER\" ,column-description: \"Start Station ID\",column-name: start_station_name, column-type:\"STRING\" ,column-description: \"Start Station Name\",column-name: start_station_latitude, column-type:\"FLOAT\" ,column-description: \"Start Station Latitude\",column-name: start_station_longitude, column-type:\"FLOAT\" ,column-description: \"Start Station Longitude\",column-name: end_station_id, column-type:\"INTEGER\" ,column-description: \"End Station ID\",column-name: end_station_name, column-type:\"STRING\" ,column-description: \"End Station Name\",column-name: end_station_latitude, column-type:\"FLOAT\" ,column-description: \"End Station Latitude\",column-name: end_station_longitude, column-type:\"FLOAT\" ,column-description: \"End Station Longitude\",column-name: bikeid, column-type:\"INTEGER\" ,column-description: \"Bike ID\",column-name: usertype, column-type:\"STRING\" ,column-description: \"User Type (Customer = 24-hour pass or 7-day pass user, Subscriber = Annual Member)\",column-name: birth_year, column-type:\"INTEGER\" ,column-description: \"Year of Birth\",column-name: gender, column-type:\"STRING\" ,column-description: \"Gender (unknown, male, female)\",column-name: customer_plan, column-type:\"STRING\" ,column-description: \"The name of the plan that determines the rate charged for the trip\"', metadata={'dataset': 'new_york_citibike', 'table': 'citibike_trips', 'table_description': \" The table 'citibike_trips' in the dataset 'new_york_citibike' contains information about bike trips in New York City. Each row in the table represents a single trip and includes details such as trip duration, start and end times, station IDs and names, bike ID, user type, birth year, gender, and customer plan. This data can be used to analyze bike usage patterns, identify popular routes, and plan for future bike infrastructure improvements.\"}), 0.4380399687081188)\n",
      "(Document(page_content='Dataset name: \\'london_bicycles\\', Dataset description:\\'None\\', Table name:\"cycle hire\", Table description:\\' The table \"cycle hire\" in the dataset \"london_bicycles\" provides information about bicycle trips in London. Each row in the table represents a single bike trip. The table includes the following columns:\\n\\n- rental_id: Unique identifier for each bike trip.\\n- duration: Duration of the bike trip in seconds.\\n- duration_ms: Duration of the bike trip in milliseconds.\\n- bike_id: Unique identifier for each bike.\\n- bike_model: Model of the bike used for the trip.\\n- end_date: Date and time when the bike trip ended.\\n- end_station_id: Unique identifier for the station where the bike trip ended.\\n- end_station_name: Name of the station where the bike trip ended.\\n- start_date: Date and time when the bike trip started.\\n- start_station_id: Unique identifier for the station where the bike trip started.\\n- start_station_name: Name of the station where the bike trip started.\\n- end_station_logical_terminal: Logical terminal for the station where the bike trip ended.\\n- start_station_logical_terminal: Logical terminal for the station where the bike trip started.\\n- end_station_priority_id: Priority ID for the station where the bike trip ended.\\'Schema attributes: column-name: rental_id, column-type:\"INTEGER\" ,column-description: \"\",column-name: duration, column-type:\"INTEGER\" ,column-description: \"Duration of the bike trip in seconds.\",column-name: duration_ms, column-type:\"INTEGER\" ,column-description: \"Duration of the bike trip in milliseconds.\",column-name: bike_id, column-type:\"INTEGER\" ,column-description: \"\",column-name: bike_model, column-type:\"STRING\" ,column-description: \"\",column-name: end_date, column-type:\"TIMESTAMP\" ,column-description: \"\",column-name: end_station_id, column-type:\"INTEGER\" ,column-description: \"\",column-name: end_station_name, column-type:\"STRING\" ,column-description: \"\",column-name: start_date, column-type:\"TIMESTAMP\" ,column-description: \"\",column-name: start_station_id, column-type:\"INTEGER\" ,column-description: \"\",column-name: start_station_name, column-type:\"STRING\" ,column-description: \"\",column-name: end_station_logical_terminal, column-type:\"INTEGER\" ,column-description: \"\",column-name: start_station_logical_terminal, column-type:\"INTEGER\" ,column-description: \"\",column-name: end_station_priority_id, column-type:\"INTEGER\" ,column-description: \"\"', metadata={'dataset': 'london_bicycles', 'table': 'cycle_hire', 'table_description': ' The table \"cycle hire\" in the dataset \"london_bicycles\" provides information about bicycle trips in London. Each row in the table represents a single bike trip. The table includes the following columns:\\n\\n- rental_id: Unique identifier for each bike trip.\\n- duration: Duration of the bike trip in seconds.\\n- duration_ms: Duration of the bike trip in milliseconds.\\n- bike_id: Unique identifier for each bike.\\n- bike_model: Model of the bike used for the trip.\\n- end_date: Date and time when the bike trip ended.\\n- end_station_id: Unique identifier for the station where the bike trip ended.\\n- end_station_name: Name of the station where the bike trip ended.\\n- start_date: Date and time when the bike trip started.\\n- start_station_id: Unique identifier for the station where the bike trip started.\\n- start_station_name: Name of the station where the bike trip started.\\n- end_station_logical_terminal: Logical terminal for the station where the bike trip ended.\\n- start_station_logical_terminal: Logical terminal for the station where the bike trip started.\\n- end_station_priority_id: Priority ID for the station where the bike trip ended.'}), 0.43479786453326674)\n",
      "(Document(page_content='Dataset name: \\'ml_datasets\\', Dataset description:\\'None\\', Table name:\"iris\", Table description:\\' **Table: iris**\\n\\n**Description**: The iris table contains measurements of the sepal and petal lengths and widths of three species of iris flowers.\\n\\n**Purpose**: The purpose of the iris table is to provide a dataset for machine learning algorithms to use in classification tasks.\\'Schema attributes: column-name: sepal_length, column-type:\"FLOAT\" ,column-description: \"\",column-name: sepal_width, column-type:\"FLOAT\" ,column-description: \"\",column-name: petal_length, column-type:\"FLOAT\" ,column-description: \"\",column-name: petal_width, column-type:\"FLOAT\" ,column-description: \"\",column-name: species, column-type:\"STRING\" ,column-description: \"\"', metadata={'dataset': 'ml_datasets', 'table': 'iris', 'table_description': ' **Table: iris**\\n\\n**Description**: The iris table contains measurements of the sepal and petal lengths and widths of three species of iris flowers.\\n\\n**Purpose**: The purpose of the iris table is to provide a dataset for machine learning algorithms to use in classification tasks.'}), 0.41704771928290374)\n"
     ]
    }
   ],
   "source": [
    "for i in output:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "\n",
    "def search_items(query):\n",
    "    # Your search logic here\n",
    "    # Return the search results\n",
    "    \n",
    "    # For example, let's assume we have a list of items\n",
    "\n",
    "    # Filter the items based on the query\n",
    "    if query ==\"\":\n",
    "        query=\"banks are bad\"\n",
    "    results = db.similarity_search_with_relevance_scores(query=query, k=5, threshold=0.5, return_relevance_scores=True)\n",
    "    output=[]\n",
    "    for i in results:\n",
    "        output.append(i[0].metadata['dataset']+\".\"+i[0].metadata['table'])\n",
    "        output.append(i[0].metadata['table_description'])\n",
    "    update_show=[gr.Text(visible=True,value=x) for x in output]\n",
    "\n",
    "    return update_show\n",
    "\n",
    "result_tables_list = []\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    search_phrase = gr.Textbox(label=\"Search phrase\",placeholder=\"Bicycles\")\n",
    "\n",
    "    with gr.Column():\n",
    "        for i in range(5):\n",
    "            with gr.Row():\n",
    "                table_field=gr.Text(show_label=False,visible=False)\n",
    "                description_field=gr.Textbox(show_label=False,visible=False)\n",
    "                result_tables_list.append(table_field)\n",
    "                result_tables_list.append(description_field)\n",
    "    search_phrase.change(search_items, search_phrase, result_tables_list)\n",
    "    greet_btn = gr.Button(\"Search\")\n",
    "\n",
    "    greet_btn.click()\n",
    "    greet_btn.click(search_items,search_phrase,result_tables_list)\n",
    "        \n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
